{
  "name": "fal-ai-master",
  "version": "2.0.0",
  "description": "Expert fal.ai generative media platform system with 600+ AI models (FLUX.2, GPT-Image 1.5, Veo 3.1, Sora 2, Kling 2.6, Recraft V3), client libraries (@fal-ai/client, fal-client), and serverless deployment. PROACTIVELY activate for: (1) ANY fal.ai task, (2) Image generation (FLUX.2, GPT-Image 1/1.5, SDXL, Recraft V3), (3) FLUX Kontext instruction-based image editing, (4) Video generation (Veo 3/3.1, Sora 2/Pro, Kling 2.6 Pro, LTX-2, Runway Gen-3), (5) Native audio in video (Veo 3, Kling 2.6), (6) Image-to-video animation pipelines, (7) Real-time WebSocket streaming (@fal.realtime.connect), (8) Queue-based execution (fal.subscribe, fal.queue), (9) Serverless deployment (fal.App, machine_type, keep_alive, min/max_concurrency), (10) GPU compute (T4/A10G/A100/H100/H200/B200), (11) JavaScript/TypeScript integration (@fal-ai/client), (12) Python integration (fal-client, fal_client.subscribe), (13) Storage (fal.Volume, fal.storage.upload), (14) Cost optimization and 2025 pricing ($0.025/image to $0.45/sec video). Provides: Complete model catalog, client library patterns, real-time streaming, webhook notifications, rate limiting strategies, error handling, and production deployment patterns.",
  "author": {
    "name": "Josiah Siegel",
    "email": "JosiahSiegel@users.noreply.github.com"
  },
  "homepage": "https://github.com/JosiahSiegel/claude-plugin-marketplace/tree/main/plugins/fal-ai-master",
  "repository": "https://github.com/JosiahSiegel/claude-plugin-marketplace",
  "license": "MIT",
  "keywords": [
    "fal-ai",
    "fal",
    "generative-ai",
    "image-generation",
    "video-generation",
    "flux",
    "flux-2",
    "flux-kontext",
    "gpt-image",
    "veo-3",
    "sora-2",
    "kling-2-6",
    "stable-diffusion",
    "recraft",
    "text-to-image",
    "text-to-video",
    "image-to-video",
    "native-audio",
    "serverless",
    "gpu-compute",
    "ml-deployment",
    "realtime",
    "websocket",
    "streaming",
    "queue",
    "subscribe",
    "t4",
    "a10g",
    "a100",
    "h100",
    "h200",
    "b200",
    "ai-models",
    "inference",
    "2025"
  ]
}
